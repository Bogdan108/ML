{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3v5HIUdDvY5"
      },
      "source": [
        "# HSE 2023: Mathematical Methods for Data Analysis\n",
        "\n",
        "## Homework 3\n",
        "# Luckyanchuk Bogdan BSE-213\n",
        "\n",
        "**Warning 1**: some problems require (especially the lemmatization part) significant amount of time, so **it is better to start early (!)**\n",
        "\n",
        "**Warning 2**: it is critical to describe and explain what you are doing and why, use markdown cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7t9dYtdDvZC"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIHtwV6vDvZD"
      },
      "source": [
        "## PART 1: Logit model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7XKEWcVDvZD"
      },
      "source": [
        "We consider a binary classification problem. For prediction, we would like to use a logistic regression model. For regularization we add a combination of the $l_2$ and $l_1$ penalties (Elastic Net).\n",
        "\n",
        "Each object in the training dataset is indexed with $i$ and described by pair: features $x_i\\in\\mathbb{R}^{K}$ and binary labels $y_i$. The model parametrized with bias $w_0\\in\\mathbb{R}$ and weights $w\\in\\mathbb{R}^K$. Note: Bias is included in $w$ vector\n",
        "\n",
        "The optimization problem with respect to the $w_0, w$ is the following (Logistic loss with Elastic Net regularizers):\n",
        "\n",
        "$$L(w, w_0) = \\sum_{i=1}^{N} -y_i \\log{\\sigma{(w^\\top x_i)}} - (1 - y_i) \\log{(1 - \\sigma{(w^\\top x_i)})} + \\gamma \\|w\\|_1 + \\beta \\|w\\|_2^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1eSuDKXFVZu"
      },
      "source": [
        "#### 1. [0.5 points]  Find the gradient of the Elastic Net loss and write its formulas (better in latex format). Remember what derivative sigmoid has (gradient in fact is a lot simpler than you may get using automatic tools like sympy, matlab or whatever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zjH-YnPDvZD"
      },
      "source": [
        "##### Put your markdown formulas here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\\nabla L(w, w_0) = \\frac{\\partial}{\\partial w_j}(\\sum_{i=1}^{N} -y_i \\log{\\sigma{(w^\\top x_i)}} - (1 - y_i) \\log{(1 - \\sigma{(w^\\top x_i)})}) + \\gamma \\text{sign}{(w)} + 2\\beta (w)$$\n",
        "$$\\sum_{i=1}^{N} -(\\frac{y_i}{\\sigma{(w^\\top x_i)}} -\\frac{1-y_i}{1-\\sigma{(w^\\top x_i)}})\\frac{\\partial}{\\partial w_j}\\sigma{(w^\\top x_i)} =\\sum_{i=1}^{N} -(\\frac{y_i}{\\sigma{(w^\\top x_i)}} -\\frac{1-y_i}{1-\\sigma{(w^\\top x_i)}})\\sigma{(w^\\top x_i)}(1-\\sigma{(w^\\top x_i)})x_{ij} = \\sum_{i=1}^{N}- (y_i -\\sigma{(w^\\top x_i)})x_{ij}$$\n",
        "$$\\ \\frac{\\partial}{\\partial w_j} L(w, w_0) = \\sum_{i=1}^{N}- (y_i -\\sigma{(w^\\top x_i)})x_{ij} + \\gamma \\text{sign}{(w_j)} + 2\\beta (w_j)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_lIccN_DvZE"
      },
      "source": [
        "#### 2. [0.25 points] Implement the Elastic Net loss (as a function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    clipped_x = np.clip(x, -700, 700)  # Ограничиваем x, чтобы избежать переполнения\n",
        "    return 1 / (1 + np.exp(-clipped_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QNfCtV5DvZE"
      },
      "outputs": [],
      "source": [
        "def loss(X, y, w: List[float], gamma=1., beta=1.) -> float:\n",
        "    return np.dot(-y, np.log(sigmoid(X.dot(w))+1e-15))+np.dot(-(1-y), np.log((1-sigmoid(X.dot( w))+1e-15))) + gamma*np.linalg.norm(w, ord=1) + beta*np.linalg.norm(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIVoC6UmDvZE"
      },
      "source": [
        "#### 3. [0.25 points] Implement the gradient (as a function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWqBLGRADvZE"
      },
      "outputs": [],
      "source": [
        "def get_grad(X, y, w: List[float], gamma=1., beta=1.) -> Tuple[List[float], float]:\n",
        "    grad_w = X.T.dot((sigmoid(X.dot( w))-y))  + \\\n",
        "        gamma*np.sign(w) + 2*beta*(w)\n",
        "    return grad_w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhOb8HrtDvZF"
      },
      "source": [
        "#### Check yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FxXTocHDvZF"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.multivariate_normal(np.arange(5), np.eye(5), size=10)\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "y = np.random.binomial(1, 0.42, size=10)\n",
        "w = np.random.normal(size=5 + 1)\n",
        "grad_w = get_grad(X, y, w)\n",
        "assert (np.allclose(grad_w,\n",
        "                    [-3.99447493, -1.84786723,  0.64520104,\n",
        "                     1.67059973, -5.03858487, -5.21496336],\n",
        "                    rtol=1e-2)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbqLfcrRDvZF"
      },
      "source": [
        "####  4. [1 point]  Implement gradient descent which works for both tol level and max_iter stop criteria and plot the decision boundary of the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIgiwQkjDvZF"
      },
      "source": [
        "The template provides basic sklearn API class. You are free to modify it in any convenient way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thyeux0KDvZG"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from scipy.sparse import csr_matrix, hstack\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I-mPUA6YaEH"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Logit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, beta=1.0, gamma=1.0, lr=1e-4, tolerance=1e-5, max_iter=100000, random_state=42):\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iter = max_iter\n",
        "        self.lr = lr\n",
        "        self.random_state = random_state\n",
        "        self.w = None\n",
        "        self.loss_history = None\n",
        "        self.w0 = None\n",
        "        self.indicator_ones = False\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # add weights and bias and optimize Elastic Net loss over (X,y) dataset\n",
        "        # save history of optimization steps\n",
        "        self.loss_history = []\n",
        "        self.classes_ = np.array([0,1])\n",
        "        if not isinstance(X, csr_matrix):\n",
        "            X = csr_matrix(X)\n",
        "\n",
        "        if self.indicator_ones == False:\n",
        "            self.indicator_ones = True\n",
        "            ones_column = np.ones((X.shape[0], 1))\n",
        "            X_ones = hstack([ones_column, X])\n",
        "        if self.w0 is None:\n",
        "            self.w0 = np.random.normal(0, 1, size=X_ones.shape[1])\n",
        "            self.w = self.w0.copy()\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            new_w = get_grad(X_ones, y, self.w, self.gamma, self.beta)\n",
        "            new_w = self.w - self.lr*new_w\n",
        "            diff = self.w - new_w\n",
        "            if np.linalg.norm(diff, ord=1) < self.tolerance:\n",
        "                break\n",
        "            self.w = new_w\n",
        "            self.loss_history.append(loss(X_ones, y, self.w, self.gamma, self.beta))\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        if not isinstance(X, csr_matrix):\n",
        "            X = csr_matrix(X)\n",
        "        ones_column = np.ones((X.shape[0], 1))\n",
        "        X_ones = hstack([ones_column, X])\n",
        "        predict = np.round(sigmoid(X_ones.dot(self.w) ))\n",
        "        return predict\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not isinstance(X, csr_matrix):\n",
        "            X = csr_matrix(X)\n",
        "        ones_column = np.ones((X.shape[0], 1))\n",
        "        X_ones = hstack([ones_column, X])\n",
        "        return np.array([sigmoid(X_ones.dot(self.w) ),\n",
        "                         sigmoid(-X_ones.dot(self.w))]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SJX8Y6EDvZG"
      },
      "outputs": [],
      "source": [
        "# sample data to test your model\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=180, n_features=2, n_redundant=0, n_informative=2,\n",
        "                           random_state=42, n_clusters_per_class=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u41kzwGTDvZH"
      },
      "outputs": [],
      "source": [
        "# a function to plot the decision boundary\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    fig = plt.figure()\n",
        "    X1min, X2min = X.min(axis=0)\n",
        "    X1max, X2max = X.max(axis=0)\n",
        "    x1, x2 = np.meshgrid(np.linspace(X1min, X1max, 200),\n",
        "                         np.linspace(X2min, X2max, 200))\n",
        "    ypred = model.predict(np.c_[x1.ravel(), x2.ravel()])\n",
        "    ypred = ypred.reshape(x1.shape)\n",
        "\n",
        "    plt.contourf(x1, x2, ypred, alpha=.4)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNuYbsAoDvZI"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "model = Logit(0, 0)\n",
        "model.fit(X_scaled, y)\n",
        "plot_decision_boundary(model, X_scaled, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi4WRhcADvZI"
      },
      "source": [
        "#### 5. [0.25 points] Plot loss diagram for the model, i.e. show the dependence of the loss function from the gradient descent steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyjMDAKuDvZI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(model.loss_history)\n",
        "\n",
        "plt.xlabel('Количество итераций')\n",
        "plt.ylabel('Ошибка')\n",
        "plt.title('График функции ошибки по итерациям')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FhSCAv_DvZJ"
      },
      "source": [
        "## PART 2: Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYyGsSxEDvZJ"
      },
      "source": [
        "#### 6. [2 point] Using the same dataset, train SVM Classifier from Sklearn.\n",
        "Investigate how different parameters influence the quality of the solution:\n",
        "+ Try several kernels: Linear, Polynomial, RBF (and others if you wish). Some Kernels have hypermeters: don't forget to try different.\n",
        "+ Regularization coefficient\n",
        "\n",
        "Show how these parameters affect accuracy, roc_auc and f1 score.\n",
        "Make plots for the dependencies between metrics and parameters.\n",
        "Try to formulate conclusions from the observations. How sensitive are kernels to hyperparameters? How sensitive is a solution to the regularization? Which kernel is prone to overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Разбиваем данные на тренировочную и тестовую выборки и скейлим их."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Зададим параметры для моделей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reg_coef = np.logspace(-2, -1, 50)\n",
        "gamma_coef = np.logspace(-3, 0, 50)\n",
        "degree_coef = list(range(2, 13))\n",
        "coef_coef = np.linspace(-100,100,50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Реализуем функцию для вывода граифков результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_res(param:[],result:dict, param_name):\n",
        "    plt.figure()\n",
        "    for key, value in result.items():\n",
        "        plt.plot(param, value, label=key, lw=2)\n",
        "    plt.xlabel('Значения метрик')\n",
        "    plt.ylabel('Значение параметра ' + param_name)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Исследуем Linear kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nicu_O3IDvZK"
      },
      "outputs": [],
      "source": [
        "lin_result = {'Roc_auc': [], 'Accuracy': [], 'F1_score': []}\n",
        "\n",
        "for coef in reg_coef:\n",
        "    clf = SVC(verbose=False, probability=True, kernel='linear', C=coef)\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    pred = clf.predict(X_test_scaled)\n",
        "    proba = clf.predict_proba(X_test_scaled)\n",
        "    lin_result['Accuracy'].append(accuracy_score(y_test, pred))\n",
        "    lin_result['F1_score'].append(f1_score(y_test, pred, average='macro'))\n",
        "    lin_result['Roc_auc'].append(roc_auc_score(y_test, proba[:, 1]))\n",
        "show_res(reg_coef, lin_result, 'C')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На графике "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Исследуем Poly kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poly_param = {'C':reg_coef, 'gamma':gamma_coef, 'coef0':coef_coef, 'degree':degree_coef}\n",
        "\n",
        "for param_name,param_coef in poly_param.items():\n",
        "    poly_result = {'Roc_auc': [], 'Accuracy': [], 'F1_score': []}\n",
        "    for coef in param_coef:\n",
        "        clf = SVC(verbose=False, probability=True, kernel='poly',**{param_name:coef})\n",
        "        clf.fit(X_train_scaled, y_train)\n",
        "        pred = clf.predict(X_test_scaled)\n",
        "        proba = clf.predict_proba(X_test_scaled)\n",
        "        poly_result['Accuracy'].append(accuracy_score(y_test, pred))\n",
        "        poly_result['F1_score'].append(f1_score(y_test, pred, average='macro'))\n",
        "        poly_result['Roc_auc'].append(roc_auc_score(y_test, proba[:, 1]))\n",
        "    show_res(param_coef, poly_result, param_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Исследуем RBF kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rbf_param = {'C':reg_coef, 'gamma':gamma_coef}\n",
        "\n",
        "for param_name,param_coef in rbf_param.items():\n",
        "    rbf_result = {'Roc_auc': [], 'Accuracy': [], 'F1_score': []}\n",
        "    for coef in param_coef:\n",
        "        clf = SVC(verbose=False, probability=True, kernel='rbf',**{param_name:coef})\n",
        "        clf.fit(X_train_scaled, y_train)\n",
        "        pred = clf.predict(X_test_scaled)\n",
        "        proba = clf.predict_proba(X_test_scaled)\n",
        "        rbf_result['Accuracy'].append(accuracy_score(y_test, pred))\n",
        "        rbf_result['F1_score'].append(f1_score(y_test, pred, average='macro'))\n",
        "        rbf_result['Roc_auc'].append(roc_auc_score(y_test, proba[:, 1]))\n",
        "    show_res(param_coef, rbf_result, param_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY8q6JdCDvZK"
      },
      "source": [
        "## PART 3: Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD4xKhYfDvZK"
      },
      "source": [
        "#### 7. [1.75 point] Form the dataset\n",
        "\n",
        "We are going to form a dataset that we will use in the following tasks for binary and multiclass classification\n",
        "\n",
        "0. Choose **six** authors that you like (specify who you've chosen) and download the <a href=\"https://www.kaggle.com/d0rj3228/russian-literature?select=prose\">relevant data</a> from **prose** section\n",
        "1. Build your own dataset for these authors:\n",
        "    * divide each text into sentences such that we will have two columns: *sentence* and *target author*, each row will contain one sentence and one target\n",
        "    * drop sentences where N symbols in a sentence < 15\n",
        "    * fix random state and randomly choose sentences in the folowing proportion \"5k : 15k : 8k : 11k : 20k : 3k\" for the authors respectively\n",
        "    \n",
        "    sample data may look like:\n",
        "    \n",
        "    <center>\n",
        "    <table>\n",
        "        <tr>\n",
        "            <th> sentence </th>\n",
        "            <th> author </th>\n",
        "        </tr>\n",
        "        <tr><td> Несколько лет тому назад в одном из своих поместий жил старинный русской барин, Кирила Петрович Троекуров. </td><td> Пушкин </td><td>\n",
        "        <tr><td> Уже более недели приезжий господин жил в городе, разъезжая по вечеринкам и обедам и таким образом проводя, как говорится, очень приятно время. </td><td> Гоголь </td><td>\n",
        "        <tr><td> ... </td><td> ... </td><td>\n",
        "        <tr><td> Я жил недорослем, гоняя голубей и играя в чехарду с дворовыми мальчишками. </td><td> Пушкин </td><td>         \n",
        "    </table>\n",
        "</center>\n",
        "     \n",
        "2. Preprocess (tokenize and clean) the dataset\n",
        "    * tokenize, remove all stop words (nltk.corpus.stopwords), punctuation (string.punctuation) and numbers\n",
        "    * convert to lower case and apply either stemming or lemmatization of the words (on your choice)\n",
        "    * vectorize words using both **bag of words** and **tf-idf** (use sklearn)\n",
        "    * observe and describe the difference between vectorized output (what do numbers look like after transformations and what do they represent?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для формирования данных были выбраны следующие авторы: Достоевский, Толстой, Чехов, Тургенев, Пушкин, Брюсов "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build dataset for these authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVStbeQ8DvZL"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import os\n",
        "import string # for work with strings\n",
        "\n",
        "authors_dir = os.listdir('Authors')\n",
        "texts = []\n",
        "authors = []\n",
        "sentences = []\n",
        "author_sentence = []\n",
        "\n",
        "# Проходим по каждой папке с авторами и перебираем текст\n",
        "for auth in authors_dir:\n",
        "    if not auth.startswith('.'):\n",
        "        for text in os.listdir(('Authors/'+auth)):\n",
        "            if not text.startswith('.'):\n",
        "                with open(os.path.join(f\"Authors/{auth}/\"+text), encoding='utf-8', mode='r') as file:\n",
        "                    texts.append(file.read())\n",
        "                    authors.append(auth)\n",
        "\n",
        "# Разбиваем полученные произведения на предложения с привязкой к автору\n",
        "sent_tokenizer = nltk.PunktSentenceTokenizer()\n",
        "for text in range(len(texts)):\n",
        "    senten = nltk.sent_tokenize((texts[text].replace(\"\\n\", \"\")),language=\"russian\")\n",
        "    senten = [sen for sen in senten if (len(sen) >= 15)]\n",
        "    sentences.extend(senten)\n",
        "    author_sentence.extend([authors[text]]*len(senten))\n",
        "\n",
        "df = pd.DataFrame({'sentences': sentences, 'author': author_sentence})\n",
        "\n",
        "# Создадим массив пропорций для разбиения данных и сортируем по убыванию, чтобы выбранные\n",
        "# пропорции были меньше количество предложений у авторов\n",
        "proportions = [5000, 15000, 8000, 11000, 20000, 3000]\n",
        "proportions.sort(reverse=True)\n",
        "\n",
        "# value_counts().index вернет список авторов в порядке количества их произведений (по убыванию)\n",
        "sampled_df = pd.DataFrame()\n",
        "for author, propotion in zip(df[\"author\"].value_counts().index,proportions):\n",
        "    sample = df[df[\"author\"] == author].sample(n=propotion,random_state=42)\n",
        "    sampled_df = pd.concat([sampled_df,sample])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(sampled_df['author'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Preprocess (tokenize and clean) the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import re\n",
        "\n",
        "# punctuation characters\n",
        "string.punctuation\n",
        "# define stemmer\n",
        "stemmer = SnowballStemmer(\"russian\")\n",
        "# define word tokenizer\n",
        "word_tokenizer = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('russian')\n",
        "\n",
        "token_sentences = []\n",
        "for sent in sampled_df['sentences'].tolist():\n",
        "    sent = sent.lower() # convert words in a text to lower case\n",
        "    sent = sent.translate(str.maketrans('','',string.punctuation))#remove punctuation\n",
        "    sent = sent.translate(str.maketrans('','',string.digits))\n",
        "    tokens     = word_tokenizer.tokenize(sent) # splits the text into tokens (words)\n",
        "    tokens = [stemmer.stem(word) for word in tokens if (word not in stop_words and not word.isdigit())]\n",
        "    token_sentences.append(' '.join(tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_df = pd.DataFrame({'sentences': token_sentences, 'author': sampled_df['author'].to_list()})\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(token_df['sentences'])\n",
        "bf_vector = vectorizer.transform(token_df['sentences'])\n",
        "print(bf_vector.todense()[1:2])\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(token_df['sentences'])\n",
        "tf_idf_vector = vectorizer.transform(token_df['sentences'])\n",
        "print(tf_idf_vector.todense()[1:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На основе результатов работы двух методов векторизации можно увидеть, что метод CountVectorizer() формирует матрицу,где по столбцам стоят все слова из выборки, а по строкам количество вхождений данных слов в предложение. В методе TfidfVectorizer() мы видим другую ситуацию, в отличие от предыдущего метода здесь стоят числа с плавающей точкой, так как "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuTi3rvnDvZL"
      },
      "source": [
        "###  Binary classification\n",
        "\n",
        "#### 8. [2 point] Train model using Logistic Regression (your own) and SVC (SVM can be taken from sklearn)\n",
        "\n",
        "* choose *two* authors from the dataset that you have formed in the previous task\n",
        "* check the balance of the classes\n",
        "* divide the data into train and test samples with 0.7 split rate (don't forget to fix the random state)\n",
        "* using GridSearchCV - find the best parameters for the models (by F1 score) and use it in the next tasks\n",
        "* make several plots to address the dependence between F1 score and parameters\n",
        "* plot confusion matrix for train and test samples\n",
        "* compute some relevant metrics for test sample (useful to check the seminars 5 and 6, use sklearn)\n",
        "* make conclusions about the performance of your models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZUP1HqFDvZL"
      },
      "outputs": [],
      "source": [
        "# choose two authors from the dataset that we have formed in the previous task\n",
        "position = (token_df['author'] == 'Turgenev') | (\n",
        "    token_df['author'] == 'Bryusov')\n",
        "two_authors = tf_idf_vector[position]\n",
        "two_authors_y = token_df['author'][position]\n",
        "two_authors_y = [1 if x == 'Turgenev' else 0 for x in two_authors_y]\n",
        "\n",
        "# check the balance of the classes\n",
        "print(token_df['author'][position].value_counts())\n",
        "print(\"Доля высказваний Тургенева: \", sum(\n",
        "    two_authors_y) / (two_authors).shape[0])\n",
        "print(\"Доля высказваний Брюсова: \",\n",
        "      ((two_authors).shape[0] - sum(two_authors_y)) / (two_authors).shape[0])\n",
        "\n",
        "# divide the data into train and test samples with 0.7 split rate\n",
        "train_texts, test_texts, train_y, test_y = train_test_split(two_authors, np.array(\n",
        "    two_authors_y), test_size=0.3, random_state=42, stratify=two_authors_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как мы видим, данные классы сбалансированы, так как доля числа предложений из произведений Тургенева примерно равна доле числа высказываний Брюсова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_results(test_y, pred, proba):\n",
        "    print(\"Precision: {0:6.2f}\".format(precision_score(test_y, pred, average='macro')))\n",
        "    print(\"Recall: {0:6.2f}\".format(recall_score(test_y, pred, average='macro')))\n",
        "    print(\"F1-measure: {0:6.2f}\".format(f1_score(test_y, pred, average='macro')))\n",
        "    print(\"Accuracy: {0:6.2f}\".format(accuracy_score(test_y, pred)))\n",
        "    print(\"ROC-AUC  =  {0:6.2f}\".format(roc_auc_score(test_y, proba[:,0])))\n",
        "    print('\\n')\n",
        "    labels = ['Bryusov','Turgenev']\n",
        "    sns.heatmap(data=confusion_matrix(test_y, pred), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(\"Confusion matrix \")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params_logit =  {'beta': np.linspace(0,1, 8),'gamma': np.linspace(0,1, 8), 'lr': np.linspace(0, 1, 8)}\n",
        "svr = Logit(max_iter=1000)\n",
        "clf = GridSearchCV(svr, params_logit, scoring = 'f1', cv=3)\n",
        "clf.fit(train_texts, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters:  {'beta': 0.0, 'gamma': 0.0, 'lr': 1.0}\n",
            "Precision:   0.82\n",
            "Recall:   0.82\n",
            "F1-measure:   0.82\n",
            "Accuracy:   0.83\n",
            "ROC-AUC  =    0.87\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = clf.predict(test_texts)\n",
        "proba  = clf.predict_proba(test_texts)\n",
        "print('Best parameters: ', clf.best_params_)\n",
        "show_results(test_y, pred, proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Найдем зависимости f1 меры от парамеров для Logit модели. Для этого проитерируемся по диапазону каждого параметра с зафиксированными лучшими другими параметрами, найденными с помошью GridSearch в предыдущем пункте "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_f1(param:[], para_res:[],param_name):\n",
        "    plt.figure()\n",
        "    plt.plot(param, para_res, label=key, lw=2)\n",
        "    plt.xlabel('Значения метрик')\n",
        "    plt.ylabel('Значение параметра ' + param_name)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "expression cannot contain assignment, perhaps you meant \"==\"? (1345994047.py, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[118], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    svr = Logit(max_iter=1000, 'beta'=beta)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
          ]
        }
      ],
      "source": [
        "beta_result = []\n",
        "for beta in params_logit['beta']:\n",
        "    svr = Logit(max_iter=1000, 'beta'=beta)\n",
        "    clf.fit(train_texts, train_y)\n",
        "    pred = clf.predict(test_texts)\n",
        "    beta_result.append(f1_score(test_y, pred, average='macro'))\n",
        "show_f1(params_logit['beta'],beta_result,'beta' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gama_result = []\n",
        "for gama in params_logit['gama']:\n",
        "    svr = Logit(max_iter=1000, 'gama'=gama)\n",
        "    clf.fit(train_texts, train_y)\n",
        "    pred = clf.predict(test_texts)\n",
        "    gama_result.append(f1_score(test_y, pred, average='macro'))\n",
        "show_f1(params_logit['gama'],gama_result,'gama' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_result = []\n",
        "for lr in params_logit['gama']:\n",
        "    svr = Logit(max_iter=1000, 'lr'=lr)\n",
        "    clf.fit(train_texts, train_y)\n",
        "    pred = clf.predict(test_texts)\n",
        "    lr_result.append(f1_score(test_y, pred, average='macro'))\n",
        "show_f1(params_logit['lr'],lr_result,'learning rate' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'),'C':np.linspace(0.001, 1, 5),}\n",
        "clf = GridSearchCV(SVC(probability=True, verbose = False),parameters, scoring = 'f1', cv=2)\n",
        "clf.fit(train_texts, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'beta': 0.0, 'gamma': 0.0, 'lr': 1.0}\n",
            "Precision:   0.82\n",
            "Recall:   0.82\n",
            "F1-measure:   0.82\n",
            "Accuracy:   0.83\n",
            "ROC-AUC  =    0.87\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(clf.best_params_)\n",
        "pred = clf.predict(test_texts)\n",
        "proba  = clf.predict_proba(test_texts)\n",
        "show_results(test_y, pred, proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В данном задании код для поиска лучших параметров и их визуализации взят с семинара №6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G1kt0qbDvZL"
      },
      "source": [
        "#### 9. [1 point] Analysing ROC AUC\n",
        "\n",
        "It is possible to control the proportion of statistical errors of different types using different thresholds for choosing a class. Plot ROC curves for Logistic Regression and SVC, show the threshold on ROC curve plots. Choose such a threshold that your models have no more than 30% of false positive errors rate. Pay attention to `thresholds` parameter in sklearn roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ2GZ8-uDvZL"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-qubaK4DvZM"
      },
      "source": [
        "### Multiclass logit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJQone-LDvZM"
      },
      "source": [
        "#### 10. [1 point] Take the One-VS-One classifier (use sklearn) and apply to Logit model (one you've made in the 4th task) in order to get multiclass linear classifier\n",
        "\n",
        "*It is possible to use sklearn model instead of your own one but with a penalty of 0.5*\n",
        "\n",
        "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html\">OneVsOneClassifier</a>\n",
        "\n",
        "* use the data you got at the previous step for 6 authors\n",
        "* divide the data into train and test samples with 0.7 split rate\n",
        "* using GridSearchCV - find the best parameters for the models (by F1 score)\n",
        "* plot confusion matrix for train and test samples\n",
        "* compute relevant metrics for test sample (use sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4lR8qJ7DvZM"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HW3_v7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
